{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PegasosQSVC - DGA Botnet detection\n",
        "\n",
        "Madjid Tehrani\n",
        "Cybersec-DMS (DMS GmbH)\n",
        "#https://www.cybersec-dms.com/\n",
        "Copyright Â© 2023, DMS GmbH. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this\n",
        "software and associated documentation files (the \"Software\"), for academic research purposes, subject to the following conditions:\n",
        "the above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.   \n"
      ],
      "metadata": {
        "id": "-keYwsg_F9vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pylatexenc\n",
        "!pip install qiskit --upgrade;\n",
        "!pip install qiskit-aer;\n",
        "!pip install qiskit-terra;\n",
        "!pip install -U azure-quantum\n",
        "!pip install -U azure-quantum[qiskit]\n",
        "!pip install -U qiskit_machine_learning"
      ],
      "metadata": {
        "id": "eebZFnRX1Ya4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to load a file from a publicly accessible URL\n",
        "import urllib.request\n",
        "\n",
        "def download_file(url, save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)\n",
        "    print(f'File successfully downloaded to {save_path}.')"
      ],
      "metadata": {
        "id": "C7jUFJd41vAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.visualization import plot_histogram\n",
        "from qiskit.tools.monitor import job_monitor\n",
        "from azure.quantum.qiskit import AzureQuantumProvider\n",
        "from qiskit import QuantumCircuit, execute, Aer\n",
        "from qiskit import *\n",
        "from qiskit.utils import QuantumInstance\n",
        "from azure.quantum import Workspace\n",
        "\n",
        "provider = AzureQuantumProvider (\n",
        "    resource_id = \"/subscriptions/YOUR-ID/resourceGroups/AzureQuantum/providers/Microsoft.Quantum/Workspaces/YourWorkspace\",\n",
        "    location = \"eastus\"\n",
        ")\n",
        "\n",
        "print(\"This workspace's targets:\")\n",
        "for backend in provider.backends():\n",
        "    print(\"- \" + backend.name())\n",
        "\n",
        "workspace = Workspace (\n",
        "    subscription_id = \"YOUR-ID\",\n",
        "    resource_group = \"AzureQuantum\",\n",
        "    name = \"YourWorkspace\",\n",
        "    location = \"eastus\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "qon-jfok1_UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80fc2580-9518-47be-a8a0-f1d2307e7e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:azure.identity._internal.decorators:EnvironmentCredential.get_token failed: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
            "Visit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot this issue.\n",
            "WARNING:azure.identity._internal.get_token_mixin:ImdsCredential.get_token failed: ManagedIdentityCredential authentication unavailable. The requested identity has not been assigned to this resource.\n",
            "WARNING:azure.identity._internal.decorators:ManagedIdentityCredential.get_token failed: ManagedIdentityCredential authentication unavailable. The requested identity has not been assigned to this resource.\n",
            "WARNING:azure.identity._internal.get_token_mixin:VisualStudioCodeCredential.get_token failed: Failed to get Azure user details from Visual Studio Code. Currently, the VisualStudioCodeCredential only works with the Azure Account extension version 0.9.11 and earlier. A long-term fix is in progress, see https://github.com/Azure/azure-sdk-for-python/issues/25713\n",
            "WARNING:azure.identity._internal.decorators:VSCodeCredential.get_token failed: Failed to get Azure user details from Visual Studio Code. Currently, the VisualStudioCodeCredential only works with the Azure Account extension version 0.9.11 and earlier. A long-term fix is in progress, see https://github.com/Azure/azure-sdk-for-python/issues/25713\n",
            "WARNING:azure.identity._internal.decorators:AzureCliCredential.get_token failed: Azure CLI not found on path\n",
            "WARNING:azure.identity._internal.decorators:AzurePowerShellCredential.get_token failed: PowerShell is not installed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This workspace's targets:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:msal.oauth2cli.authcode:Found no browser in current environment. If this program is being run inside a container which has access to host network (i.e. started by `docker run --net=host -it ...`), you can use browser on host to visit the following link. Otherwise, this auth attempt would either timeout (current timeout setting is None) or be aborted by CTRL+C. Auth URI: https://login.microsoftonline.com/d689239e-c492-40c6-b391-2c5951d31d14/oauth2/v2.0/authorize?client_id=04b07795-8ddb-461a-bbee-02f9e1bf7b46&response_type=code&redirect_uri=http%3A%2F%2Flocalhost%3A46697&scope=https%3A%2F%2Fquantum.microsoft.com%2F.default+offline_access+openid+profile&state=bKsyPxjmQrEquIBv&code_challenge=36_YwzfqP8SeLJPObIoGGVs2Omr-IhvEv7sjdSHLtng&code_challenge_method=S256&nonce=cb4293b30896c682ef5f90f52af8d5eba93601369826b09d3700fa47f4a0c627&client_info=1&prompt=select_account\n",
            "WARNING:azure.identity._internal.interactive:InteractiveBrowserCredential.get_token failed: Authentication failed: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code R65SR24GU to authenticate.\n",
            "- ionq.simulator\n",
            "- ionq.simulator\n",
            "- ionq.simulator\n",
            "- ionq.qpu\n",
            "- ionq.qpu\n",
            "- ionq.qpu\n",
            "- ionq.qpu.aria-1\n",
            "- ionq.qpu.aria-1\n",
            "- ionq.qpu.aria-1\n",
            "- quantinuum.hqs-lt-s1-apival\n",
            "- quantinuum.hqs-lt-s1-apival\n",
            "- quantinuum.sim.h1-1sc\n",
            "- quantinuum.sim.h1-1sc\n",
            "- quantinuum.hqs-lt-s2-apival\n",
            "- quantinuum.hqs-lt-s2-apival\n",
            "- quantinuum.sim.h1-2sc\n",
            "- quantinuum.sim.h1-2sc\n",
            "- quantinuum.hqs-lt-s1-sim\n",
            "- quantinuum.hqs-lt-s1-sim\n",
            "- quantinuum.sim.h1-1e\n",
            "- quantinuum.sim.h1-1e\n",
            "- quantinuum.hqs-lt-s2-sim\n",
            "- quantinuum.hqs-lt-s2-sim\n",
            "- quantinuum.sim.h1-2e\n",
            "- quantinuum.sim.h1-2e\n",
            "- quantinuum.hqs-lt-s1\n",
            "- quantinuum.hqs-lt-s1\n",
            "- quantinuum.qpu.h1-1\n",
            "- quantinuum.qpu.h1-1\n",
            "- quantinuum.hqs-lt-s2\n",
            "- quantinuum.hqs-lt-s2\n",
            "- quantinuum.qpu.h1-2\n",
            "- quantinuum.qpu.h1-2\n",
            "- rigetti.sim.qvm\n",
            "- rigetti.qpu.aspen-m-3\n",
            "- microsoft.estimator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create IonQ simulator and QPU backends\n",
        "ionq_simulator_backend = provider.get_backend(\"ionq.simulator\")\n",
        "ionq_qpu_backend = provider.get_backend(\"ionq.qpu\")\n",
        "\n",
        "# Create Rigetti simulator and QPU backends\n",
        "rigetti_simulator_backend = provider.get_backend(\"rigetti.sim.qvm\")\n",
        "rigetti_qpu_backend = provider.get_backend(\"rigetti.qpu.aspen-m-3\")\n",
        "\n",
        "# Create Quantinuum simulator and QPU backends\n",
        "Quantinuum_simulator_backend = provider.get_backend(\"quantinuum.sim.h1-2sc\")\n",
        "Quantinuum_qpu_backend = provider.get_backend(\"quantinuum.qpu.h1-2\")\n",
        "\n",
        "# Create QASM simulator\n",
        "backend = Aer.get_backend('qasm_simulator')"
      ],
      "metadata": {
        "id": "1c4thNW5F1gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap, ZFeatureMap\n",
        "from qiskit.utils import algorithm_globals\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
        "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
        "from qiskit.algorithms.optimizers import SLSQP, SPSA\n",
        "from qiskit.circuit.library import TwoLocal\n",
        "from qiskit import Aer, transpile\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import concurrent.futures\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Binarizer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "n_features = 7\n",
        "training_size = 700\n",
        "test_size = 300\n",
        "feature_dim = 7\n",
        "num_samples = 1000\n",
        "datafilename=\"BotnetDgaDataset_1000.csv\"\n",
        "resultname=\"result_BotnetDgaDataset_1000.txt\"\n",
        "cwd=os.getcwd()\n",
        "mycsv=cwd+\"/\"+datafilename\n",
        "\n",
        "download_file('https://aq5efd7d2644dd406cb3ec2d.blob.core.windows.net/dga/BotnetDgaDataset_1000.csv', mycsv)\n",
        "\n",
        "def load_data(filepath):\n",
        "\n",
        "    with open(filepath) as csv_file:\n",
        "        data_file = csv.reader(csv_file)\n",
        "        temp = next(data_file)\n",
        "        n_samples = 1000\n",
        "        n_features = 7\n",
        "        target_names = np.array(temp[2:])\n",
        "        data = np.empty((n_samples, n_features))\n",
        "        target = np.empty((n_samples,), dtype=np.int)\n",
        "\n",
        "        for i, ir in enumerate(data_file):\n",
        "            data[i] = np.asarray(ir[:-1], dtype=np.float64)\n",
        "            target[i] = np.asarray(ir[-1], dtype=np.int)\n",
        "\n",
        "    return data, target, target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF7RvfBz3MGf",
        "outputId": "02d5240d-af56-40bb-e892-cb66b00264d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully downloaded to /content/BotnetDgaDataset_1000.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#code from https://ieee-dataport.org/open-access/botnet-dga-dataset\n",
        "def _convert_data_dataframe(data, target,\n",
        "                            feature_names, target_names):\n",
        "    data_df = pd.DataFrame(data, columns=feature_names)\n",
        "    target_df = pd.DataFrame(target, columns=target_names)\n",
        "    combined_df = pd.concat([data_df, target_df], axis=1)\n",
        "    X = combined_df[feature_names]\n",
        "    y = combined_df[target_names]\n",
        "    if y.shape[1] == 1:\n",
        "        y = y.iloc[:, 0]\n",
        "    return combined_df, X, y\n",
        "\n",
        "\n",
        "def load_botnetdga(*, as_frame=False):\n",
        "\n",
        "    data, target, target_names = load_data('BotnetDgaDataset_1000.csv')\n",
        "\n",
        "\n",
        "\n",
        "    feature_names = ['MinREBotnets',\n",
        "                     'CharLength',\n",
        "                     'TreeNewFeature',\n",
        "                     'nGramReputation_Alexa']\n",
        "\n",
        "    frame = None\n",
        "    target_columns = ['target', ]\n",
        "    if as_frame:\n",
        "        frame, data, target = _convert_data_dataframe(data,\n",
        "                                                      target,\n",
        "                                                      feature_names,\n",
        "                                                      target_columns)\n",
        "\n",
        "    return data, target\n",
        "\n",
        "\n",
        "def botnetdga(training_size, test_size, n,\n",
        "              standardize=False, pca=False, scale=False, plot_data=False,\n",
        "              binarize=False):\n",
        "\n",
        "    class_labels = [r'benign', r'dga']\n",
        "\n",
        "    data, target = load_botnetdga()\n",
        "    sample_train, sample_test, label_train, label_test = \\\n",
        "        train_test_split(data, target, train_size=training_size, test_size=test_size, random_state=7)\n",
        "\n",
        "    # print(\"\\n load_botnetdga sample_train = \\n\")\n",
        "    # print(sample_train)\n",
        "    # print(\"\\n load_botnetdga sample_test = \\n\")\n",
        "    # print(sample_test)\n",
        "\n",
        "    # Now we standardize for gaussian around 0 with unit variance\n",
        "    if standardize:\n",
        "        std_scale = StandardScaler().fit(sample_train)\n",
        "        sample_train = std_scale.transform(sample_train)\n",
        "        sample_test = std_scale.transform(sample_test)\n",
        "\n",
        "        # print(\"\\n standardize sample_train = \\n\")\n",
        "        # print(sample_train)\n",
        "        # print(\"\\n standardize sample_test = \\n\")\n",
        "        # print(sample_test)\n",
        "\n",
        "    # Now reduce number of features to number of qubits\n",
        "    if pca:\n",
        "        pca = PCA(n_components=n).fit(sample_train)\n",
        "        sample_train = pca.transform(sample_train)\n",
        "        sample_test = pca.transform(sample_test)\n",
        "\n",
        "        # print(\"\\n pca sample_train = \\n\")\n",
        "        # print(sample_train)\n",
        "        # print(\"\\n pca sample_test = \\n\")\n",
        "        # print(sample_test)\n",
        "\n",
        "    # Scale to the range (-1,+1)\n",
        "    if scale:\n",
        "        samples = np.append(sample_train, sample_test, axis=0)\n",
        "        minmax_scale = MinMaxScaler((-1, 1)).fit(samples)\n",
        "        sample_train = minmax_scale.transform(sample_train)\n",
        "        sample_test = minmax_scale.transform(sample_test)\n",
        "\n",
        "        # print(\"\\n scale sample_train = \\n\")\n",
        "        # print(sample_train)\n",
        "        # print(\"\\n scale sample_test = \\n\")\n",
        "        # print(sample_test)\n",
        "\n",
        "    if binarize:\n",
        "        med = np.median(np.append(sample_train, sample_test, axis=0), axis=0)\n",
        "\n",
        "        # print(\"\\n binarize np.append(sample_train, sample_test, axis=0) = \\n\")\n",
        "        # print(np.append(sample_train, sample_test, axis=0)[:5])\n",
        "        # print(\"\\n binarize med = \\n\")\n",
        "        # print(med)\n",
        "\n",
        "        transformer = Binarizer(threshold=med)\n",
        "        # print(\"\\n binarize transformer = \\n\")\n",
        "        # print(transformer)\n",
        "\n",
        "        sample_train = transformer.transform(sample_train)\n",
        "        sample_test = transformer.transform(sample_test)\n",
        "\n",
        "        # print(\"\\n binarize sample_train = \\n\")\n",
        "        # print(sample_train)\n",
        "        # print(\"\\n binarize sample_test = \\n\")\n",
        "        # print(sample_test)\n",
        "\n",
        "    # Pick training size number of samples from each distro\n",
        "    training_input = {key: (sample_train[label_train == k, :])[:training_size]\n",
        "                      for k, key in enumerate(class_labels)}\n",
        "    test_input = {key: (sample_test[label_test == k, :])[:test_size]\n",
        "                  for k, key in enumerate(class_labels)}\n",
        "\n",
        "    return sample_train, training_input, test_input, class_labels"
      ],
      "metadata": {
        "id": "MQIoaFHe3QEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import time\n",
        "start = time.perf_counter()\n",
        "\n",
        "# BotnetDGA data set\n",
        "plot_data = False\n",
        "training_size = 700\n",
        "test_size = 300\n",
        "feature_dim = 7\n",
        "standardize = False\n",
        "pca = False\n",
        "scale = False\n",
        "binarize = False\n",
        "\n",
        "\n",
        "\n",
        "# random_seed = 10598\n",
        "# shots = 1024\n",
        "# seed = 1376\n",
        "# aqua_globals.random_seed = seed\n",
        "\n",
        "sample_train, training_input, test_input, class_labels = botnetdga(training_size=training_size,\n",
        "                                                                    test_size=test_size,\n",
        "                                                                    n=feature_dim,\n",
        "                                                                    standardize=standardize,\n",
        "                                                                    pca=pca,\n",
        "                                                                    scale=scale,\n",
        "                                                                    plot_data=plot_data,\n",
        "                                                                    binarize=binarize)\n",
        "\n",
        "# print(\"\\n sample_train = \\n\")\n",
        "# print(sample_train)\n",
        "# print(\"\\n training_input = \\n\")\n",
        "# print(training_input)\n",
        "# print(\"\\n test_input = \\n\")\n",
        "# print(test_input)\n",
        "# print(\"\\n class_labels = \\n\")\n",
        "# print(class_labels)\n",
        "\n",
        "optimizer1 = SPSA()\n",
        "#optimizer2 = ADAM()\n",
        "#optimizer3 = AQGD()\n",
        "#optimizer4 = CG()\n",
        "#optimizer5 = COBYLA()\n",
        "#optimizer6 = L_BFGS_B()\n",
        "#optimizer7 = GSLS()\n",
        "#optimizer8 = NELDER_MEAD()\n",
        "#optimizer9 = NFT()\n",
        "#optimizer10 = P_BFGS()\n",
        "#optimizer11 = POWELL()\n",
        "#optimizer12 = SLSQP()\n",
        "#optimizer13 = TNC()\n",
        "\n",
        "nFeature = 7\n",
        "\n",
        "#feature_map1 = RawFeatureVector(nFeature)\n",
        "#feature_map2 = PauliFeatureMap(nFeature)\n",
        "feature_map3 = ZFeatureMap(nFeature)\n",
        "#feature_map4 = ZZFeatureMap(nFeature)\n",
        "\n",
        "#var_form11 = TwoLocal(feature_map1.num_qubits, ['ry', 'rz'], 'cz')\n",
        "#var_form12 = RealAmplitudes(feature_map1.num_qubits)\n",
        "#var_form13 = EfficientSU2(feature_map1.num_qubits)\n",
        "#var_form14 = ExcitationPreserving(feature_map1.num_qubits)\n",
        "\n",
        "#var_form21 = TwoLocal(feature_map2.num_qubits, ['ry', 'rz'], 'cz')\n",
        "#var_form22 = RealAmplitudes(feature_map2.num_qubits)\n",
        "#var_form23 = EfficientSU2(feature_map2.num_qubits)\n",
        "#var_form24 = ExcitationPreserving(feature_map2.num_qubits)\n",
        "\n",
        "#var_form31 = TwoLocal(feature_map3.num_qubits, ['ry', 'rz'], 'cz')\n",
        "var_form32 = RealAmplitudes(feature_map3.num_qubits)\n",
        "#var_form33 = EfficientSU2(feature_map3.num_qubits)\n",
        "#var_form34 = ExcitationPreserving(feature_map3.num_qubits)\n",
        "\n",
        "#var_form41 = TwoLocal(feature_map4.num_qubits, ['ry', 'rz'], 'cz')\n",
        "#var_form42 = RealAmplitudes(feature_map4.num_qubits)\n",
        "#var_form43 = EfficientSU2(feature_map4.num_qubits)\n",
        "#var_form44 = ExcitationPreserving(feature_map4.num_qubits)"
      ],
      "metadata": {
        "id": "Y6KCF6KM3UAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is part of Qiskit. But to handle exception we changed it. Yuo dont need it if you use AER. This is an acedemic test example and we dont intend to change the code out of its license, however to run over other simulators and real devices its a neccessary change.\n",
        "\n",
        "\"\"\"Pegasos Quantum Support Vector Classifier.\"\"\"\n",
        "import time\n",
        "import signal\n",
        "\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "from qiskit.utils import algorithm_globals\n",
        "from sklearn.base import ClassifierMixin\n",
        "\n",
        "from qiskit_machine_learning.algorithms  import SerializableModelMixin\n",
        "from qiskit_machine_learning import QiskitMachineLearningError\n",
        "from qiskit_machine_learning.kernels import FidelityQuantumKernel, QuantumKernel, BaseKernel\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class PegasosQSVC(ClassifierMixin, SerializableModelMixin):\n",
        "    r\"\"\"\n",
        "    Implements Pegasos Quantum Support Vector Classifier algorithm. The algorithm has been\n",
        "    developed in [1] and includes methods ``fit``, ``predict`` and ``decision_function`` following\n",
        "    the signatures\n",
        "    of `sklearn.svm.SVC <https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html>`_.\n",
        "    This implementation is adapted to work with quantum kernels.\n",
        "\n",
        "    **Example**\n",
        "\n",
        "    .. code-block:: python\n",
        "\n",
        "        quantum_kernel = FidelityQuantumKernel()\n",
        "\n",
        "        pegasos_qsvc = PegasosQSVC(quantum_kernel=quantum_kernel)\n",
        "        pegasos_qsvc.fit(sample_train, label_train)\n",
        "        pegasos_qsvc.predict(sample_test)\n",
        "\n",
        "    **References**\n",
        "        [1]: Shalev-Shwartz et al., Pegasos: Primal Estimated sub-GrAdient SOlver for SVM.\n",
        "            `Pegasos for SVM <https://home.ttic.edu/~nati/Publications/PegasosMPB.pdf>`_\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    FITTED = 0\n",
        "    UNFITTED = 1\n",
        "    # pylint: disable=invalid-name\n",
        "    def __init__(\n",
        "        self,\n",
        "        quantum_kernel: BaseKernel | None = None,\n",
        "        C: float = 1.0,\n",
        "        num_steps: int = 1000,\n",
        "        precomputed: bool = False,\n",
        "        seed: int | None = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            quantum_kernel: a quantum kernel to be used for classification. Has to be ``None`` when\n",
        "                a precomputed kernel is used.\n",
        "            C: Positive regularization parameter. The strength of the regularization is inversely\n",
        "                proportional to C. Smaller ``C`` induce smaller weights which generally helps\n",
        "                preventing overfitting. However, due to the nature of this algorithm, some of the\n",
        "                computation steps become trivial for larger ``C``. Thus, larger ``C`` improve\n",
        "                the performance of the algorithm drastically. If the data is linearly separable\n",
        "                in feature space, ``C`` should be chosen to be large. If the separation is not\n",
        "                perfect, ``C`` should be chosen smaller to prevent overfitting.\n",
        "\n",
        "            num_steps: number of steps in the Pegasos algorithm. There is no early stopping\n",
        "                criterion. The algorithm iterates over all steps.\n",
        "            precomputed: a boolean flag indicating whether a precomputed kernel is used. Set it to\n",
        "                ``True`` in case of precomputed kernel.\n",
        "            seed: a seed for the random number generator\n",
        "\n",
        "        Raises:\n",
        "            ValueError:\n",
        "                - if ``quantum_kernel`` is passed and ``precomputed`` is set to ``True``. To use\n",
        "                a precomputed kernel, ``quantum_kernel`` has to be of the ``None`` type.\n",
        "            TypeError:\n",
        "                - if ``quantum_kernel`` neither instance of\n",
        "                  :class:`~qiskit_machine_learning.kernels.BaseKernel` nor ``None``.\n",
        "        \"\"\"\n",
        "\n",
        "        if precomputed:\n",
        "            if quantum_kernel is not None:\n",
        "                raise ValueError(\"'quantum_kernel' has to be None to use a precomputed kernel\")\n",
        "        else:\n",
        "            if quantum_kernel is None:\n",
        "                quantum_kernel = FidelityQuantumKernel()\n",
        "\n",
        "        self._quantum_kernel = quantum_kernel\n",
        "        self._precomputed = precomputed\n",
        "        self._num_steps = num_steps\n",
        "        if seed is not None:\n",
        "            algorithm_globals.random_seed = seed\n",
        "\n",
        "        if C > 0:\n",
        "            self.C = C\n",
        "        else:\n",
        "            raise ValueError(f\"C has to be a positive number, found {C}.\")\n",
        "\n",
        "        # these are the parameters being fit and are needed for prediction\n",
        "        self._alphas: Dict[int, int] | None = None\n",
        "        self._x_train: np.ndarray | None = None\n",
        "        self._n_samples: int | None = None\n",
        "        self._y_train: np.ndarray | None = None\n",
        "        self._label_map: Dict[int, int] | None = None\n",
        "        self._label_pos: int | None = None\n",
        "        self._label_neg: int | None = None\n",
        "\n",
        "        # added to all kernel values to include an implicit bias to the hyperplane\n",
        "        self._kernel_offset = 1\n",
        "\n",
        "        # for compatibility with the base SVC class. Set as unfitted.\n",
        "        self.fit_status_ = PegasosQSVC.UNFITTED\n",
        "\n",
        "    # pylint: disable=invalid-name\n",
        "    def fit(\n",
        "        self, X: np.ndarray, y: np.ndarray, sample_weight: np.ndarray | None = None\n",
        "    ) -> \"PegasosQSVC\":\n",
        "        \"\"\"Fit the model according to the given training data.\n",
        "\n",
        "        Args:\n",
        "            X: Train features. For a callable kernel (an instance of\n",
        "               :class:`~qiskit_machine_learning.kernels.BaseKernel`) the shape\n",
        "               should be ``(n_samples, n_features)``, for a precomputed kernel the shape should be\n",
        "               ``(n_samples, n_samples)``.\n",
        "            y: shape (n_samples), train labels . Must not contain more than two unique labels.\n",
        "            sample_weight: this parameter is not supported, passing a value raises an error.\n",
        "\n",
        "        Returns:\n",
        "            ``self``, Fitted estimator.\n",
        "\n",
        "        Raises:\n",
        "            ValueError:\n",
        "                - X and/or y have the wrong shape.\n",
        "                - X and y have incompatible dimensions.\n",
        "                - y includes more than two unique labels.\n",
        "                - Pre-computed kernel matrix has the wrong shape and/or dimension.\n",
        "\n",
        "            NotImplementedError:\n",
        "                - when a sample_weight which is not None is passed.\n",
        "        \"\"\"\n",
        "        # check whether the data have the right format\n",
        "        if np.ndim(X) != 2:\n",
        "            raise ValueError(\"X has to be a 2D array\")\n",
        "        if np.ndim(y) != 1:\n",
        "            raise ValueError(\"y has to be a 1D array\")\n",
        "        if len(np.unique(y)) != 2:\n",
        "            raise ValueError(\"Only binary classification is supported\")\n",
        "        if X.shape[0] != y.shape[0]:\n",
        "            raise ValueError(\"'X' and 'y' have to contain the same number of samples\")\n",
        "        if self._precomputed and X.shape[0] != X.shape[1]:\n",
        "            raise ValueError(\n",
        "                \"For a precomputed kernel, X should be in shape (n_samples, n_samples)\"\n",
        "            )\n",
        "        if sample_weight is not None:\n",
        "            raise NotImplementedError(\n",
        "                \"Parameter 'sample_weight' is not supported. All samples have to be weighed equally\"\n",
        "            )\n",
        "        # reset the fit state\n",
        "        self.fit_status_ = PegasosQSVC.UNFITTED\n",
        "\n",
        "        # the algorithm works with labels in {+1, -1}\n",
        "        self._label_pos = np.unique(y)[0]\n",
        "        self._label_neg = np.unique(y)[1]\n",
        "        self._label_map = {self._label_pos: +1, self._label_neg: -1}\n",
        "\n",
        "        # the training data are later needed for prediction\n",
        "        self._x_train = X\n",
        "        self._y_train = y\n",
        "        self._n_samples = X.shape[0]\n",
        "\n",
        "        # empty dictionary to represent sparse array\n",
        "        self._alphas = {}\n",
        "\n",
        "        t_0 = datetime.now()\n",
        "        # training loop\n",
        "        for step in range(1, self._num_steps + 1):\n",
        "            # for every step, a random index (determining a random datum) is fixed\n",
        "            i = algorithm_globals.random.integers(0, len(y))\n",
        "\n",
        "            value = self._compute_weighted_kernel_sum(i, X, training=True)\n",
        "\n",
        "            if (self._label_map[y[i]] * self.C / step) * value < 1:\n",
        "                # only way for a component of alpha to become non zero\n",
        "                self._alphas[i] = self._alphas.get(i, 0) + 1\n",
        "\n",
        "        self.fit_status_ = PegasosQSVC.FITTED\n",
        "\n",
        "        logger.debug(\"fit completed after %s\", str(datetime.now() - t_0)[:-7])\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    # pylint: disable=invalid-name\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform classification on samples in X.\n",
        "\n",
        "        Args:\n",
        "            X: Features. For a callable kernel (an instance of\n",
        "               :class:`~qiskit_machine_learning.kernels.BaseKernel`) the shape\n",
        "               should be ``(m_samples, n_features)``, for a precomputed kernel the shape should be\n",
        "               ``(m_samples, n_samples)``. Where ``m`` denotes the set to be predicted and ``n`` the\n",
        "               size of the training set. In that case, the kernel values in X have to be calculated\n",
        "               with respect to the elements of the set to be predicted and the training set.\n",
        "\n",
        "        Returns:\n",
        "            An array of the shape (n_samples), the predicted class labels for samples in X.\n",
        "\n",
        "        Raises:\n",
        "            QiskitMachineLearningError:\n",
        "                - predict is called before the model has been fit.\n",
        "            ValueError:\n",
        "                - Pre-computed kernel matrix has the wrong shape and/or dimension.\n",
        "        \"\"\"\n",
        "\n",
        "        t_0 = datetime.now()\n",
        "        values = self.decision_function(X)\n",
        "        y = np.array([self._label_pos if val > 0 else self._label_neg for val in values])\n",
        "        logger.debug(\"prediction completed after %s\", str(datetime.now() - t_0)[:-7])\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "    def decision_function(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Evaluate the decision function for the samples in X.\n",
        "\n",
        "        Args:\n",
        "            X: Features. For a callable kernel (an instance of\n",
        "               :class:`~qiskit_machine_learning.kernels.BaseKernel`) the shape\n",
        "               should be ``(m_samples, n_features)``, for a precomputed kernel the shape should be\n",
        "               ``(m_samples, n_samples)``. Where ``m`` denotes the set to be predicted and ``n`` the\n",
        "               size of the training set. In that case, the kernel values in X have to be calculated\n",
        "               with respect to the elements of the set to be predicted and the training set.\n",
        "\n",
        "        Returns:\n",
        "            An array of the shape (n_samples), the decision function of the sample.\n",
        "\n",
        "        Raises:\n",
        "            QiskitMachineLearningError:\n",
        "                - the method is called before the model has been fit.\n",
        "            ValueError:\n",
        "                - Pre-computed kernel matrix has the wrong shape and/or dimension.\n",
        "        \"\"\"\n",
        "        if self.fit_status_ == PegasosQSVC.UNFITTED:\n",
        "            raise QiskitMachineLearningError(\"The PegasosQSVC has to be fit first\")\n",
        "        if np.ndim(X) != 2:\n",
        "            raise ValueError(\"X has to be a 2D array\")\n",
        "        if self._precomputed and self._n_samples != X.shape[1]:\n",
        "            raise ValueError(\n",
        "                \"For a precomputed kernel, X should be in shape (m_samples, n_samples)\"\n",
        "            )\n",
        "\n",
        "        values = np.zeros(X.shape[0])\n",
        "        for i in range(X.shape[0]):\n",
        "            values[i] = self._compute_weighted_kernel_sum(i, X, training=False)\n",
        "\n",
        "        return values\n",
        "\n",
        "#changed part is here-it needs an exception handling that if a circuit fails, we dont lose the experiment\n",
        "    def _compute_weighted_kernel_sum(self, index: int, X: np.ndarray, training: bool) -> float:\n",
        "        \"\"\"Helper function to compute the weighted sum over support vectors used for both training\n",
        "        and prediction with the Pegasos algorithm.\n",
        "\n",
        "        Args:\n",
        "            index: fixed index distinguishing some datum\n",
        "            X: Features\n",
        "            training: flag indicating whether the loop is used within training or prediction\n",
        "\n",
        "        Returns:\n",
        "            Weighted sum of kernel evaluations employed in the Pegasos algorithm\n",
        "        \"\"\"\n",
        "        # non-zero indices corresponding to the support vectors\n",
        "        support_indices = list(self._alphas.keys())\n",
        "\n",
        "        # for training\n",
        "        if training:\n",
        "            # support vectors\n",
        "            x_supp = X[support_indices]\n",
        "        # for prediction\n",
        "        else:\n",
        "            x_supp = self._x_train[support_indices]\n",
        "\n",
        "        try:\n",
        "            start_time = time.time()\n",
        "            if not self._precomputed:\n",
        "                # evaluate kernel function only for the fixed datum and the support vectors\n",
        "                kernel = self._quantum_kernel.evaluate(X[index], x_supp) + self._kernel_offset\n",
        "            else:\n",
        "                kernel = X[index, support_indices]\n",
        "            elapsed_time = time.time() - start_time\n",
        "            if elapsed_time > 4:\n",
        "                # kernel computation took too long, terminate this round\n",
        "                return 0  # or any other default value\n",
        "        except Exception as e:\n",
        "            # log the exception message\n",
        "            print(f\"Exception occurred while computing kernel: {e}\")\n",
        "            # signal that this round failed\n",
        "            return 0  # or any other default value\n",
        "\n",
        "\n",
        "        # map the training labels of the support vectors to {-1,1}\n",
        "        y = np.array(list(map(self._label_map.get, self._y_train[support_indices])))\n",
        "        # weights for the support vectors\n",
        "        alphas = np.array(list(self._alphas.values()))\n",
        "        # this value corresponds to a sum of kernel values weighted by their labels and alphas\n",
        "        value = np.sum(alphas * y * kernel)\n",
        "\n",
        "        return value\n",
        "\n",
        "\n",
        "#enc of change\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @property\n",
        "    def quantum_kernel(self) -> BaseKernel:\n",
        "        \"\"\"Returns quantum kernel\"\"\"\n",
        "        return self._quantum_kernel\n",
        "\n",
        "    @quantum_kernel.setter\n",
        "    def quantum_kernel(self, quantum_kernel: BaseKernel):\n",
        "        \"\"\"\n",
        "        Sets quantum kernel. If previously a precomputed kernel was set, it is reset to ``False``.\n",
        "        \"\"\"\n",
        "\n",
        "        self._quantum_kernel = quantum_kernel\n",
        "        # quantum kernel is set, so we assume the kernel is not precomputed\n",
        "        self._precomputed = False\n",
        "\n",
        "        # reset training status\n",
        "        self._reset_state()\n",
        "\n",
        "    @property\n",
        "    def num_steps(self) -> int:\n",
        "        \"\"\"Returns number of steps in the Pegasos algorithm.\"\"\"\n",
        "        return self._num_steps\n",
        "\n",
        "    @num_steps.setter\n",
        "    def num_steps(self, num_steps: int):\n",
        "        \"\"\"Sets the number of steps to be used in the Pegasos algorithm.\"\"\"\n",
        "        self._num_steps = num_steps\n",
        "\n",
        "        # reset training status\n",
        "        self._reset_state()\n",
        "\n",
        "    @property\n",
        "    def precomputed(self) -> bool:\n",
        "        \"\"\"Returns a boolean flag indicating whether a precomputed kernel is used.\"\"\"\n",
        "        return self._precomputed\n",
        "\n",
        "    @precomputed.setter\n",
        "    def precomputed(self, precomputed: bool):\n",
        "        \"\"\"Sets the pre-computed kernel flag. If ``True`` is passed then the previous kernel is\n",
        "        cleared. If ``False`` is passed then a new instance of\n",
        "        :class:`~qiskit_machine_learning.kernels.FidelityQuantumKernel` is created.\"\"\"\n",
        "        self._precomputed = precomputed\n",
        "        if precomputed:\n",
        "            # remove the kernel, a precomputed will\n",
        "            self._quantum_kernel = None\n",
        "        else:\n",
        "            # re-create a new default quantum kernel\n",
        "            self._quantum_kernel = FidelityQuantumKernel()\n",
        "\n",
        "        # reset training status\n",
        "        self._reset_state()\n",
        "\n",
        "    def _reset_state(self):\n",
        "        \"\"\"Resets internal data structures used in training.\"\"\"\n",
        "        self.fit_status_ = PegasosQSVC.UNFITTED\n",
        "        self._alphas = None\n",
        "        self._x_train = None\n",
        "        self._n_samples = None\n",
        "        self._y_train = None\n",
        "        self._label_map = None\n",
        "        self._label_pos = None\n",
        "        self._label_neg = None\n"
      ],
      "metadata": {
        "id": "6760jTST3X0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PegasosQSVC\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_blobs\n",
        "datafilename=\"BotnetDgaDataset_1000.csv\"\n",
        "resultname=\"result_BotnetDgaDataset_pegasos_1000.txt\"\n",
        "cwd=os.getcwd()\n",
        "mycsv=cwd+\"/\"+datafilename\n",
        "print(mycsv)\n",
        "def load_data(filepath):\n",
        "    with open(filepath) as csv_file:\n",
        "        data_file = csv.reader(csv_file)\n",
        "        temp = next(data_file)\n",
        "        n_samples = 1000\n",
        "        n_features = 7\n",
        "        data = np.empty((n_samples, n_features))\n",
        "        target = np.empty((n_samples,), dtype=int)\n",
        "\n",
        "        for i, ir in enumerate(data_file):\n",
        "            data[i] = np.asarray(ir[:-1], dtype=np.float64)\n",
        "            target[i] = np.asarray(ir[-1], dtype=int)\n",
        "\n",
        "    return data, target\n",
        "dgafeatures, labels = load_data(mycsv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBvlO-OQ3j4J",
        "outputId": "602afbd8-2404-4c77-a67c-5527e6a1aa4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BotnetDgaDataset_1000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation for pegasos\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "features = MinMaxScaler(feature_range=(0, np.pi)).fit_transform(dgafeatures)\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(\n",
        "    features, labels, train_size=700, shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "KKrN8u2J3nNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parameter setting for Pegasos\n",
        "# number of qubits is equal to the number of features\n",
        "num_qubits = 7\n",
        "\n",
        "# number of steps performed during the training procedure\n",
        "tau = 100\n",
        "\n",
        "# regularization parameter\n",
        "C = 1000"
      ],
      "metadata": {
        "id": "9tWf9igd3qfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing/;\n",
        "#1-The default fidelity instantiated in FidelityQuantumKernel\n",
        "#2-A quantum kernel created from ZFeatureMap\n",
        "from qiskit import BasicAer\n",
        "from qiskit.circuit.library import ZFeatureMap\n",
        "from qiskit.utils import algorithm_globals\n",
        "\n",
        "from qiskit_machine_learning.kernels import FidelityQuantumKernel, QuantumKernel\n",
        "\n",
        "algorithm_globals.random_seed = 12345\n",
        "\n",
        "feature_map = ZFeatureMap(feature_dimension=num_qubits, reps=1)\n",
        "\n",
        "qkernel = FidelityQuantumKernel(feature_map=feature_map)\n"
      ],
      "metadata": {
        "id": "9l0RYqHu3vJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(backend)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM5tWKH-uCEU",
        "outputId": "4c3edaf9-5764-4995-f3dd-640ef49b3813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qasm_simulator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#backend=rigetti_qpu_backend\n",
        "#backend=rigetti_simulator_backend\n",
        "#backend = Aer.get_backend('qasm_simulator')\n",
        "#backend = Quantinuum_simulator_backend\n",
        "from qiskit.circuit.library import RealAmplitudes, ZFeatureMap, ZZFeatureMap, EfficientSU2\n",
        "\n",
        "num_features =7\n",
        "feature_map=ZFeatureMap(num_features,reps=1)\n",
        "qkernel_backend = QuantumKernel(feature_map=feature_map, quantum_instance=backend)"
      ],
      "metadata": {
        "id": "BamSR4NO3wmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#running model\n",
        "#if you use our modified version not the qiskit original version, then comment the below line\n",
        "from qiskit_machine_learning.algorithms import PegasosQSVC\n",
        "import time\n",
        "pegasos_start=time.perf_counter()\n",
        "pegasos_qsvc = PegasosQSVC(quantum_kernel=qkernel_backend, C=C, num_steps=tau)\n",
        "# training\n",
        "pegasos_qsvc.fit(train_features, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk2UZAV132Jm",
        "outputId": "1701a5d1-f094-4a9f-d790-147b2322dc32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<qiskit_machine_learning.algorithms.classifiers.pegasos_qsvc.PegasosQSVC at 0x7eccacba0220>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "pegasos_score = pegasos_qsvc.score(test_features, test_labels)\n",
        "pegasos_end=time.perf_counter()\n",
        "\n",
        "print(f\"PegasosQSVC Accuracy: {pegasos_score}\")\n",
        "print(f\"PegasosQSVC Time: {pegasos_end-pegasos_start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rKP3N8Z4B7Y",
        "outputId": "57141895-51e5-43f1-e9f8-be1bf1f205b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PegasosQSVC Accuracy: 0.8233333333333334\n",
            "PegasosQSVC Time: 90.52283525499979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Warning - this cell is for calculation of average accuracy and time for 10 times running - not possible to do it out of AER due to speed and cost of running\n",
        "# Setting up the loop to run the PegasosQSVC 10 times and collect accuracies and times\n",
        "\n",
        "num_runs = 10\n",
        "pegasos_scores = []\n",
        "pegasos_times = []\n",
        "\n",
        "for _ in range(num_runs):\n",
        "    pegasos_start = time.perf_counter()\n",
        "\n",
        "    pegasos_qsvc = PegasosQSVC(quantum_kernel=qkernel_backend, C=C, num_steps=tau)\n",
        "    pegasos_qsvc.fit(train_features, train_labels)\n",
        "    pegasos_score = pegasos_qsvc.score(test_features, test_labels)\n",
        "\n",
        "    pegasos_end = time.perf_counter()\n",
        "\n",
        "    pegasos_scores.append(pegasos_score)\n",
        "    pegasos_times.append(pegasos_end - pegasos_start)\n",
        "\n",
        "# Calculating average accuracy and average time\n",
        "average_accuracy = sum(pegasos_scores) / num_runs\n",
        "average_time = sum(pegasos_times) / num_runs\n",
        "\n",
        "average_accuracy, average_time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOaZevx9K1sd",
        "outputId": "291b3eb1-b66d-4542-d6ef-68405eefeaee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7393333333333333, 59.373291305700015)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}